---
output: 
 html_document:
  theme: readable
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(matlib)
```

##  An incoherent (Dutch Book) series of bets:
Suppose we are asked to assign the probabilities for $3$, mutually exclusive events. Let $E_{1}$, $E_{2}$, $E_{3}$ be the disjoint events and $p_{1}$, $p_{2}$, and $p_3$ the probabilities we associate with each event. More simply, $p_{i}$ is the probability of event $E_{i}$ occurring. We assign the following probabilities to each corresponding event:
```{r, echo = TRUE}
p1 <- .3
p2 <- .1
p3 <- .4
```

We can construct our probabilities in an $n\times n$ matrix denoted $R$. Note that by constructing the matrix in this way we can account for the positive gain for the outcome of each event $E_{i}$, and the complement negative gains of each event $E_{i}^{c}$. Given this information, we can also assume that the better would take advantage of this information and thus place a stake $s_{n}$ on all possible bets $p_{i}$.
```{r, echo = TRUE}
R <- matrix(c(1 - p1,   - p2,   - p3,
                - p1, 1 - p2,   - p3,
                - p1,   - p2, 1 - p3), 
            nrow = 3)
R
```
Thus, we can say the total gains $G_{n}$ is the difference between the sum of the total stakes $S_{n}$ and the sum of the $n$ negative outcome $S_{n}$ stakes paid to the bookkeeper, i.e. it is the sum of negative bets $-p_{i}S_{n}$, such that $G_{n} = S_{n} - \sum_{1}^{n}p_{i}S_{n}$.

If we apply some arbitrary numerical stake $s$ to each possible event $p_{i}$,
```{r, echo = TRUE}
s <- c(5, 2, 7)
s
```
we then have a set $R$ of probabilities corresponding to a set $s_{n}$ of stakes, and can solve for system of linear equations. This will provide a corresponding gain $G$, the product of $Rs$, such that $G = Rs$.
```{r, echo = TRUE}
G <- solve(a = R, b = s)
G
```
Note that our net gain $G$ is equal to
```{r, echo = TRUE}
round(sum(G))
```
However, this is an incredibly odd set of circumstances. Something is clearly amiss.

We have managed to obtain a net positive gain $G$ despite placing a stake on all possible bets available. It can actually be shown that no matter the outcome, nor the size of the bet, we will _always_ have a positive net gain value. Yet, this is obviously not a result of clairvoyance. Rather, this is due to the fact that our initial probability judgements of the $3$ disjoint events $E_{i}$ were _incoherent_ with respect to Kolmogorovâ€™s probability axiom $P(A\cap, ...,\cap A) = 1$. Critically, the set of probabilities that we assigned to each event $E_{i}$ do not sum to $1$:
```{r, echo = TRUE}
sum(p1 + p2 + p3)
```
This also means that our $n\times n$ matrix $R$ is invertible,
```{r}
matlib::inv(R)
```
Consequently, an $n\times n$ identity matrix $I$ can be formed from the multiplication of the $n\times n$ matrix $R$ with its inverse $R^{-1}$.

Note that, for those unaware, an identity matrix is a matrix where all the diagonals of a matrix are $1$'s, and the rest of the elements contain only $0$'s. It is, broadly speaking, a convenient tool used for matrix manipulations. Below is a clear example of what a standard $n\times n$ identity matrix $I$ looks like:
```{r, echo = FALSE}
I <- diag(c(1, 1, 1))
I
```
and can be shown to be a 'do nothing' matrix by, for example, solving the following,
```{r}
solve(I, s)
```
as the multiplication does not change the values of $s$, such that $I\times s = s$.

Nevertheless, let us confirm whether our matrix $R$ conforms to these conditions, such that $I = R^{-1}R$. Intuitively, this can be thought of as a soft proof for whether a system of linear equations is solvable if, for example, $R$ is brought to the other side of the equation, i.e. to see whether we can solve for $s$. We multiply each side of by its inverse, resulting in $R^{-1}Rs=R^{-1}G$, and thus $I\times s = s =R^{-1}G$
```{r, echo = TRUE}
I <- round(inv(R)%*%R)
I
```
The result of applying $R^{-1}R$ clearly mirrors the standard identity matrix example given prior. 

To return to the point of this section, then, it is crucial to note that if the event probabilities are incoherent, and thus do indeed lead to an invertible matrix, we can solve for an unknown set of stakes $s_{n}$ by equating it with the product of a set of definite gains $G_{n}$ and their corresponding event probabilities $R_{i}$. For example, say we want a desired net gain $G_{n}$ for each series of bets $R_{i}$, regardless of the outcome. We decide to provide the following definite gains $G_{n}$ for each stake $s_{n}$,
```{r, echo = TRUE}
G <- c(3, 1, 4)
G
```
This then enables us to solve for the linear transformation of $s_{n}$, by bringing $R$ over to the other side of the equation, inverting it, and setting $s = R^{-1}G$:
```{r}
s_solved <- solve(a = inv(R), b = G)
s_solved
```
This specific set of conditions enable us to set the stakes $s_{n}$ in such a way that guarantees for a positive gain, no matter the future outcome.

Intuitively speaking, we can further interpret this in a geometric sense: the total 'area' of our set of disjoint probabilities fails to induce a single, whole sample space, where $P(A\cap, ...,\cap A) \neq 1$. Thus, this means that the rows and columns of our matrix are not dependent and, as a corollary, the determinant of the matrix $R$ is $|{R}| > 0$, as evidence by
```{r, echo = TRUE}
det(R)
```
Accordingly, our net gain $\sum_{1}^{n}G_{i}$ is constantly net positive. It is now obvious why this process is so often used by sports bookkeepers and casinos to ensure a net gain, regardless of the losses. 

## A coherent series of bets:
It is clear that we are obliged to constrain the total sum area of our independent probabilities to be $= 1$, such that $P(A\cap, ...,\cap A) = 1$. In contrast to the previous example then, here we will assign probability judgements that conform to Kolmogorov's axiom $P(A\cap, ...,\cap A) = 1$. Note that the sum of probabilities $p_{i}$ now equals to $1$.
```{r A coherent bet, echo = TRUE}
p1 <- .3
p2 <- .3
p3 <- .4

sum(p1 + p2 + p3)
```

Again, we can conveniently put these event probabilities in the form of an $n\times n$ matrix $R$ to present all possible joint negative betting outcomes, while simultaneously representing the realised disjoint event,
```{r, echo = TRUE}
R <- matrix(c(1 - p1,   - p2,   - p3,
                - p1, 1 - p2,   - p3,
                - p1,   - p2, 1 - p3), 
            nrow = 3)
R
```
However, because we ensured that $P(A\cap, ...,\cap A) = 1$, where all disjoint events sum to a probability of $1$, the matrix $R$ is now not invertible. An identity matrix $I$ cannot, therefore, be formed, as $I \ne R^{-1}R$.

Moreover, now that the sum of probabilities is coherent, it will always result in a net gain of $0$ for any arbitrary series of stakes $s$. To illustrate this, we randomly sample $3$ values between $1:10000$:
```{r, echo = TRUE}
s <- sample(x = 1:10000, size = 3, replace = TRUE)
s
```
Accordingly, the gains for each bet equal,
```{r, echo = TRUE}
G <- R%*%s
G
```
and, decisively, despite the relatively high stakes on each bet compared to the previous examples, notice that the net overall gain $G$ maintains to be a constant $0$:
```{r, echo = TRUE}
round(sum(G))
```